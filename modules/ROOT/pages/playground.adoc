= Playground

In directory https://github.com/neo4j-contrib/neo4j-spark-connector/tree/5.0/examples[examples] you'll find two useful notebooks that allows you to test Neo4j and PySpark in a cloud-to-cloud environment using Neo4j sandboxes and Google colab.

image::colab-to-sandbox.png[Colab/PySpark to Neo4j sandbox architecture, align="center"]

== The notebooks

These notebooks contain a set of examples that explain how the Neo4j Spark connector can fit into your data-driven workflow, and mostly important they allow you to test your knowledge with a set of exercises after each section.

If you have any problem feel free to write a post in the [Neo4j community forum](https://community.neo4j.com/) or in [Discord](https://discord.com/invite/neo4j).

If you want more exercises feel free to open an issue in the [GitHub repository](https://github.com/neo4j-contrib/neo4j-spark-connector).

* `neo4j_data_engineering.ipynb` file explains how to interact with the Neo4j Spark connector from a Data Engineering perspective, so how to write your Spark jobs and how to read/write data from/to Neo4j;
* `neo4j_data_science.ipynb` file explains how to interact with the Neo4j Spark connector from a Data Science perspective, so how to combine Pandas (in PySpark) with the Neo4j Graph Data Science library for highlighting frauds in a banking scenario.

=== Test your knowledge

After each session you will find an exercise that will test your knowledge as shown in the image below:

image::exercise-example.png[An exercise, align="center"]

We provide asserts that will test the output of your code and we also provide a solution that you can check by expanding the text `Show a possible solution`

Enjoy!