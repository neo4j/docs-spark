[#write-rel]
= Write a relationship

With the `relationship` option, the connector writes a DataFrame to the Neo4j database by specifying source, target nodes, and a relationship.

[WARNING]
====
To avoid deadlocks, always use a single partition (for example with `coalesce(1)`) before writing relationships to Neo4j.
====

The connector builds a Cypher query like the following:

[source, cypher]
----
UNWIND $events AS event
CREATE (source:Person)
SET source = event.source
CREATE (target:Product)
SET target = event.target
CREATE (source)-[rel:BOUGHT]->(target)
SET rel += event.rel
----

The `mode` defines whether the query uses a `CREATE` or a `MERGE` clause (see <<save-mode, save mode>>).

The way the actual query is built depends on a number of options.

[cols="4, 3a, 3a, 1"]
|===
|Option |Description |Value |Default

|`relationship.save.strategy`
|Defines the <<strategies, save strategy>> to use.
|
* `native` requires the DataFrame to use a specific schema.
* `keys` is more flexible.
|`native`

|`relationship.source.save.mode`

and

`relationship.target.save.mode`
|Define the Source <<node-save-strategies, node save mode>>, and can be set independently for source and target nodes.
|
* `Match` mode performs a `MATCH`.
* `Append` mode performs a `CREATE`.
* `Overwrite` mode performs a `MERGE`.
|`Match`

|`relationship.source.labels`

and

`relationship.target.labels`
|*Required.*

Define the labels to assign to source and target nodes.
|Colon-separated list of labels.
|_(empty)_

|`relationship.source.node.keys`

and

`relationship.target.node.keys`
|When the <<node-save-strategies, node save mode>> is `Match` or `Overwrite`, defines keys that identify the nodes.
|Comma-separated list of `key:value` pairs.
|_(empty)_

|`relationship.properties`
|When the <<strategies, save strategy>> is `keys`, defines which DataFrame columns to write as relationship properties.
|Comma-separated list of `key:value` pairs.
|_(empty)_

|`relationship.source.node.properties`

and

`relationship.target.node.properties`
|When the <<strategies, save strategy>> is `keys`, defines which DataFrame columns to write as source/target node properties.
|Comma-separated list of `key:value` pairs.
|_(empty)_
|===

[#strategies]
== Save strategies

[#strategy-native]
=== `native` strategy

The `native` strategy is useful when the DataFrame schema conforms to the <<reading.adoc#rel-schema-columns,Relationship read schema>> with the `relationship.nodes.map` option set to `false`.
This means that the DataFrame must include at least one of the `rel.[property name]`, `source.[property name]`, or `target.[property name]` columns.

[NOTE]
====
If the provided DataFrame schema doesn't conform to the required schema, meaning that none of the required columns is present,
the write fails.
====

A good use case for this mode is transferring data from a database to another one.
In fact, using the connector to xref:reading.adoc#read-rel[read a relationship] first, the resulting DataFrame has already the correct schema.

[NOTE]
====
The default save mode for source and target nodes is `Match`.
That means that the relationship can be created only if the nodes are already in your database.
====

.Read + filter + write
[source, scala, role=nocollapse]
----
val originalDf = spark.read.format("org.neo4j.spark.DataSource")
  .option("relationship", "PLAYS")
  .option("relationship.nodes.map", "false")
  .option("relationship.source.labels", "Musician")
  .option("relationship.target.labels", "Instrument")
  .load()

originalDf
  .where("`rel.experience` > 15")
  .write
  .mode("Append")
  .format("org.neo4j.spark.DataSource")
  .option("relationship", "PLAYS_WELL")
  .option("relationship.source.labels", ":ExperiencedMusician")
  .option("relationship.source.save.mode", "Append")
  .option("relationship.target.labels", "Instrument")
  .option("relationship.target.save.mode", "Append")
  .save()
----

The code in the following example creates:

* `:Musician` nodes with a `name` property
* `:Instrument` nodes with a `name` property
* `:PLAYS` relationships between `:Musician` and `:Instrument` nodes, with an `experience` property

.Native strategy, `Append` node save mode
[source, scala, role=nocollapse]
----
// Columns representing node/relationships properties
// must use the "rel.", "source.", or "target." prefix
val df = Seq(
  (12, "John Bonham", "Drums"),
  (19, "John Mayer", "Guitar"),
  (32, "John Scofield", "Guitar"),
  (15, "John Butler", "Guitar")
).toDF("rel.experience", "source.name", "target.name")

df.write
  // Create new relationships
  .mode("Append")
  .format("org.neo4j.spark.DataSource")
  // Assign a type to the relationships
  .option("relationship", "PLAYS")
  // Create source nodes and assign them a label
  .option("relationship.source.save.mode", "Append")
  .option("relationship.source.labels", ":Musician")
  // Create target nodes and assign them a label
  .option("relationship.target.save.mode", "Append")
  .option("relationship.target.labels", ":Instrument")
  .save()
----

.Equivalent Cypher query
[source, cypher]
----
UNWIND $events AS event
CREATE (source:Musician)
SET source += event.source.properties
CREATE (target:Instrument)
SET target += event.target.properties
CREATE (source)-[rel:PLAYS]->(target)
SET rel += event.rel.properties
----

The same example, using `Overwrite` as a save mode for nodes and the `node.keys` option:

.Native strategy, `Overwrite` node save mode
[source, scala, role=nocollapse]
----
// Columns representing node/relationships properties
// must use the "rel.", "source.", or "target." prefix
val df = Seq(
  (12, "John Bonham", "Drums"),
  (19, "John Mayer", "Guitar"),
  (32, "John Scofield", "Guitar"),
  (15, "John Butler", "Guitar")
).toDF("rel.experience", "source.name", "target.name")

df.write
  // Create new relationships
  .mode("Append")
  .format("org.neo4j.spark.DataSource")
  // Assign a type to the relationships
  .option("relationship", "PLAYS")
  // Overwrite source nodes and assign them a label
  .option("relationship.source.save.mode", "Overwrite")
  .option("relationship.source.labels", ":Musician")
  // Node keys are mandatory for overwrite save mode
  .option("relationship.source.node.keys", "source.name:name")
  // Overwrite target nodes and assign them a label
  .option("relationship.target.save.mode", "Overwrite")
  .option("relationship.target.labels", ":Instrument")
  // Node keys are mandatory for overwrite save mode
  .option("relationship.target.node.keys", "target.name:name")
  .save()
----

.Equivalent Cypher query
[source, cypher]
----
UNWIND $events AS event
MERGE (source:Musician {name: event.source.keys.name})
SET source += event.source.properties
MERGE (target:Instrument {name: event.target.keys.name})
SET target += event.target.properties
CREATE (source)-[rel:PLAYS]->(target)
SET rel += event.rel.properties
----

[#strategy-keys]
=== `keys` strategy

The `keys` strategy gives more control on how relationships and nodes are written.
It does not require any specific schema for the DataFrame.

As in the case of using the `native` strategy, you can specify node keys to identify nodes for the `Match` and `Overwrite` mode.
In addition, you can also specify which columns to write as node and relationship properties.

[#rel-specify-keys]
.Specify node and relationships keys
[source, scala, role=nocollapse]
----
val df = Seq(
        (12, "John Bonham", "Drums"),
        (19, "John Mayer", "Guitar"),
        (32, "John Scofield", "Guitar"),
        (15, "John Butler", "Guitar")
    ).toDF("experience", "name", "instrument")

df.write
  // Create new relationships
  .mode("Append")
  .format("org.neo4j.spark.DataSource")
  // Assign a type to the relationships
  .option("relationship", "PLAYS")
  // Use `keys` strategy
  .option("relationship.save.strategy", "keys")
  .option("relationship.properties", "experience:experience")
  // Create source nodes and assign them a label
  .option("relationship.source.save.mode", "Append")
  .option("relationship.source.labels", ":Musician")
  // Map the DataFrame columns to node properties
  .option("relationship.source.node.properties", "name:name")
  // Create target nodes and assign them a label
  .option("relationship.target.save.mode", "Append")
  .option("relationship.target.labels", ":Instrument")
  // Map the DataFrame columns to node properties
  .option("relationship.target.node.properties", "instrument:name")
  .save()
----

.Equivalent Cypher query
[source, cypher]
----
UNWIND $events AS event
CREATE (source:Musician)
SET source += event.source.properties
CREATE (target:Instrument)
SET target += event.target.properties
CREATE (source)-[rel:PLAYS]->(target)
SET rel += event.rel.properties
----

[NOTE]
====
If `key` and `value` are the same field you can specify one without the colon.
For example, if you have `.option("relationship.source.node.properties", "name:name,email:email")`, you can also write
`.option("relationship.source.node.properties", "name,email")`.
Same applies for `relationship.source.node.keys` and `relationship.target.node.keys`.
====

[#node-save-strategies]
== Node save strategies

[NOTE]
====
For `Overwrite` mode you *must have unique constraints on the keys*.
====