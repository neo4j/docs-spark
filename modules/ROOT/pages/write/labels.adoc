[#write-nodes]
= Write nodes

With the `labels` option, the connector writes a DataFrame to the Neo4j database as a set of nodes with the given labels.

The connector builds a `CREATE` or a `MERGE` Cypher query (depending on the <<save-mode, SaveMode>>) that uses the `UNWIND` clause to write a batch of rows (an `events` list with size defined by the `batch.size` option).

The code from the xref:writing.adoc#example[example] creates new nodes with the given labels.

.Append example
[source, scala]
----
df.write
  .format("org.neo4j.spark.DataSource")
  .mode(SaveMode.Append)
  .option("labels", ":Person:Customer")
  .save()
----

The code above results in the following Cypher query:

.Equivalent Cypher query
[source, cypher]
----
UNWIND $events AS event
CREATE (n:Person:Customer)
SET n += event.properties
----

With the `Overwrite` mode, you must specify the DataFrame columns to use as keys to match the nodes.
The `node.keys` option takes a comma-separated list of `key:value` pairs, where the key is the DataFrame column name and the value is the node property name.

[NOTE]
====
If `key` and `value` are the same, you can omit the `value`.
For example, `"name:name,surname:surname"` is equivalent to `"name,surname"`.
====

The same code using the `Overwrite` save mode:

.Overwrite example
[source, scala]
----
df.write
  .format("org.neo4j.spark.DataSource")
  .mode(SaveMode.Overwrite)
  .option("labels", ":Person:Customer")
  .option("node.keys", "name,surname")
  .save()
----

The code above results in the following Cypher query:

.Equivalent Cypher query
[source, cypher]
----
UNWIND $events AS event
MERGE (n:Person:Customer {
  name: event.keys.name, 
  surname: event.keys.surname
})
SET n += event.properties
----
