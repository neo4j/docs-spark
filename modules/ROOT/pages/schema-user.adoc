= User-defined schema

You can skip the automatic schema extraction process by providing a user defined schema using the `.schema()` method.

.Using user defined schema
[source,scala]
----
import org.apache.spark.sql.types.{DataTypes, StructType, StructField}
import org.apache.spark.sql.{SaveMode, SparkSession}

val spark = SparkSession.builder().getOrCreate()

(spark.read.format("org.neo4j.spark.DataSource")
  .option("url", "neo4j://localhost:7687")
  .option("authentication.basic.username", "neo4j")
  .option("authentication.basic.password", "letmein!")
  .schema(StructType(Array(StructField("id", DataTypes.StringType), StructField("name", DataTypes.StringType))))
  .option("query", "MATCH (n:Person) WITH n LIMIT 2 RETURN id(n) as id, n.name as name")
  .load()
  .show())
----

.Result of the above code
|===
|id |name

|"0"|"John Doe"
|"1"|"Jane Doe"
|===

In this way you have total control over the schema.

[[read-known-problem]]
== Known problem

Because Neo4j is a schema free database, the following scenario may occur:

[source,cypher]
----
CREATE (p1:Person {age: "32"}), (p2:Person {age: 23})
----

The same field on the same node label has two different types.

Spark doesn't like it since the DataFrame requires a schema,
meaning each column of the DataFrame needs to have its own type.

[source]
----
java.lang.ClassCastException: org.apache.spark.unsafe.types.UTF8String cannot be cast to java.lang.Long
----

In this case you can either clean up and normalize your data, or rely on the connector to
implicitly cast values to `String`.

[NOTE]
This solution is not error-proof, you might still get errors if the values cannot be coerced to String.

When the casting operation happens, this warning appears in your log, letting you know what has happened:

[source]
----
The field "age" has different types: [String, Long]
Every value will be casted to string.
----

The safest solution is to clean your data, but that is not always possible.
This is why `schema.strategy` is introduced, and you can set to `string` to get all the values
converted to string.