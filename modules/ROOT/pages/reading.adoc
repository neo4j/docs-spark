= Reading from Neo4j
:description: The chapter explains how to read data from a Neo4j database.

The connector provides three options to read data from a Neo4j database.

.Read options
[cols="1, 2, 2, 1"]
|===
|Option|Description|Value|Default

|`labels`
|Use this if you only need to xref:read/labels.adoc[read nodes] with their properties.
|Colon-separated list of node labels to read.
|_(empty)_

|`relationship`
|Use this if you need to xref:read/relationship.adoc[read relationships] along with their source and target nodes.
|Relationship type to read.
|_(empty)_

|`query`
|Use this if you need more flexibility and know how to xref:read/query.adoc[write a Cypher query].
|Cypher query with a `MATCH` clause.
|_(empty)_
|===

== Type mapping

The type mapping between Spark DataFrames and Neo4j is summarized in the xref:types.adoc[] section.

[#examples]
== Basic examples

=== `labels` option

[.tabbed-example]
====
[.include-with-Scala]
=====
.Example
[source, scala, role=nocollapse]
----
include::example$scala/read/BasicNodes.scala[tags=code]
----
=====

[.include-with-Python]
=====
.Example
[source, python, role=nocollapse]
----
include::example$python/read/basic_nodes.py[tags=code]
----
=====
====

Read the xref:read/labels.adoc[] section for more information and examples.

=== `relationship` option

[.tabbed-example]
====
[.include-with-Scala]
=====
.Example
[source, scala, role=nocollapse]
----
include::example$scala/read/BasicRelationship.scala[tags=code]
----
=====

[.include-with-Python]
=====
.Example
[source, python, role=nocollapse]
----
include::example$python/read/basic_relationship.py[tags=code]
----
=====
====

Read the xref:read/relationship.adoc[] section for more information and examples.

=== `query` option

[.tabbed-example]
====
[.include-with-Scala]
=====
.Example
[source, scala, role=nocollapse]
----
include::example$scala/read/BasicQuery.scala[tags=code]
----
=====

[.include-with-Python]
=====
.Example
[source, python, role=nocollapse]
----
include::example$python/read/basic_query.py[tags=code]
----
=====
====

Read the xref:read/query.adoc[] section for more information and examples.

== Performance considerations

If the schema is not specified, the Spark Connector uses sampling as explained in the xref:schema.adoc[] section.

Since sampling is potentially an expensive operation, consider xref:schema-user.adoc[supplying your own schema].